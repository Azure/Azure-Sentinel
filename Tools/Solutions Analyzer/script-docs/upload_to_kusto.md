# Kusto Upload Script

**Script:** `solution_analyzer_upload_to_kusto.py`

## Overview

Uploads the generated CSV files to an Azure Data Explorer (Kusto) cluster for querying and analysis. Uses managed streaming ingestion for fast uploads (the same method used by the ADX "Get Data" UI).

## Prerequisites

### 1. Azure Data Explorer Cluster

You need access to an Azure Data Explorer (Kusto) cluster with a database where you have write permissions.

### 2. Azure CLI Authentication

The script uses Azure CLI for authentication. Install Azure CLI and login:

```bash
# Install Azure CLI (if not already installed)
# See: https://docs.microsoft.com/en-us/cli/azure/install-azure-cli

# Login to Azure
az login

# If using a specific tenant
az login --tenant <tenant-id>

# Verify authentication
az account show
```

### 3. Python Environment

- Python 3.7 or higher
- Required Python packages:

```bash
pip install azure-kusto-data azure-kusto-ingest azure-identity
```

### 4. Input CSV Files

The script expects CSV files generated by the other scripts:
- `tables_reference.csv` from `collect_table_info.py`
- `connectors.csv`, `tables.csv`, `solutions.csv` from `map_solutions_connectors_tables.py`
- `solutions_connectors_tables_mapping.csv` from `map_solutions_connectors_tables.py`
- `solutions_connectors_tables_mapping_simplified.csv` from `map_solutions_connectors_tables.py`

## Running the Script

```bash
python solution_analyzer_upload_to_kusto.py --cluster <cluster_url> --database <database_name>
```

### Example

```bash
python solution_analyzer_upload_to_kusto.py \
    --cluster "https://mycluster.eastus.kusto.windows.net" \
    --database "MyDatabase"
```

## Command Line Options

| Option | Default | Description |
|--------|---------|-------------|
| `--cluster`, `-c` | (required) | Kusto cluster URL (e.g., `https://mycluster.region.kusto.windows.net`) |
| `--database`, `-d` | (required) | Kusto database name |
| `--csv-dir` | `.` (current directory) | Directory containing the CSV files |
| `--dry-run` | `False` | Show what would be done without making changes |

## Tables Created

The script creates the following tables in the Kusto database:

| CSV File | Kusto Table Name |
|----------|------------------|
| `tables_reference.csv` | `solution_analyzer_table_reference_lookup` |
| `connectors.csv` | `solution_analyzer_connectors_lookup` |
| `tables.csv` | `solution_analyzer_tables_lookup` |
| `solutions.csv` | `solution_analyzer_solutions_lookup` |
| `solutions_connectors_tables_mapping_simplified.csv` | `solution_analyzer_mapping` |
| `solutions_connectors_tables_mapping.csv` | `solutions_connectors_tables_mapping` |

## Authentication

The script uses `DefaultAzureCredential` from the Azure Identity library, which supports:

- Azure CLI authentication (`az login`)
- Managed Identity (when running in Azure)
- Environment variables
- Visual Studio Code authentication

### Authenticating with Azure CLI

```bash
# Login to Azure
az login

# If using a specific tenant
az login --tenant <tenant-id>

# Verify authentication
az account show
```

## Dry Run Mode

To preview what tables would be created without making changes:

```bash
python solution_analyzer_upload_to_kusto.py \
    --cluster "https://mycluster.eastus.kusto.windows.net" \
    --database "MyDatabase" \
    --dry-run
```

## Querying the Data in Kusto

Once uploaded, you can query the data using KQL. Here are some example queries:

### Find all tables for a solution

```kql
solution_analyzer_mapping
| where solution_name == "Microsoft 365"
| distinct table_name
```

### Find connectors by collection method

```kql
solution_analyzer_connectors_lookup
| where collection_method == "AMA"
| project connector_id, connector_title, collection_method_reason
```

### Get table metadata

```kql
solution_analyzer_table_reference_lookup
| where table_name == "SecurityEvent"
| project table_name, category, basic_logs_eligible, supports_transformations
```

### Join tables with solutions

```kql
solution_analyzer_mapping
| join kind=leftouter solution_analyzer_tables_lookup on table_name
| project solution_name, table_name, category, collection_method
```
