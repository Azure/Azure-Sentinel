# Kusto Upload Script

**Script:** `solution_analyzer_upload_to_kusto.py`

## Overview

Uploads the generated CSV files to an Azure Data Explorer (Kusto) cluster for querying and analysis. Uses managed streaming ingestion for fast uploads (the same method used by the ADX "Get Data" UI).

## Prerequisites

### 1. Azure Data Explorer Cluster

You need access to an Azure Data Explorer (Kusto) cluster with a database where you have write permissions.

### 2. Azure CLI Authentication

The script uses Azure CLI for authentication. Install Azure CLI and login:

```bash
# Install Azure CLI (if not already installed)
# See: https://docs.microsoft.com/en-us/cli/azure/install-azure-cli

# Login to Azure
az login

# If using a specific tenant
az login --tenant <tenant-id>

# Verify authentication
az account show
```

### 3. Python Environment

- Python 3.7 or higher
- Required Python packages:

```bash
pip install azure-kusto-data azure-kusto-ingest azure-identity
```

### 4. Input CSV Files

The script expects CSV files generated by the other scripts:

**From `collect_table_info.py`:**
- `tables_reference.csv` - Reference table metadata from Azure documentation

**From `map_solutions_connectors_tables.py`:**
- `connectors.csv` - Connector details with collection methods
- `tables.csv` - Table metadata with categories
- `solutions.csv` - Solution metadata
- `content_items.csv` - Content items (analytics rules, workbooks, playbooks, etc.)
- `solutions_connectors_tables_mapping.csv` - Full mapping with all fields
- `solutions_connectors_tables_mapping_simplified.csv` - Simplified mapping (solution, connector, table)
- `content_tables_mapping.csv` - Content items to tables mapping

## Running the Script

```bash
python solution_analyzer_upload_to_kusto.py --cluster <cluster_url> --database <database_name>
```

### Example

```bash
python solution_analyzer_upload_to_kusto.py \
    --cluster "https://mycluster.eastus.kusto.windows.net" \
    --database "MyDatabase"
```

## Command Line Options

| Option | Default | Description |
|--------|---------|-------------|
| `--cluster`, `-c` | (required) | Kusto cluster URL (e.g., `https://mycluster.region.kusto.windows.net`) |
| `--database`, `-d` | (required) | Kusto database name |
| `--csv-dir` | `.` (current directory) | Directory containing the CSV files |
| `--dry-run` | `False` | Show what would be done without making changes |

## Tables Created

The script creates the following tables in the Kusto database:

### Lookup Tables

| CSV File | Kusto Table Name | Description |
|----------|------------------|-------------|
| `tables_reference.csv` | `solution_analyzer_table_reference_lookup` | Reference table metadata from Azure documentation |
| `connectors.csv` | `solution_analyzer_connectors_lookup` | Connector details with collection methods |
| `tables.csv` | `solution_analyzer_tables_lookup` | Table metadata with categories |
| `solutions.csv` | `solution_analyzer_solutions_lookup` | Solution metadata |
| `content_items.csv` | `solution_analyzer_content_items_lookup` | Content items (analytics rules, workbooks, etc.) |

### Mapping Tables

| CSV File | Kusto Table Name | Description |
|----------|------------------|-------------|
| `solutions_connectors_tables_mapping_simplified.csv` | `solution_analyzer_mapping` | Simplified mapping (solution, connector, table) |
| `solutions_connectors_tables_mapping.csv` | `solution_analyzer_full_mapping` | Full mapping with all fields |
| `content_tables_mapping.csv` | `solution_analyzer_content_tables_mapping` | Content items to tables mapping |

## Authentication

The script uses `DefaultAzureCredential` from the Azure Identity library, which supports:

- Azure CLI authentication (`az login`)
- Managed Identity (when running in Azure)
- Environment variables
- Visual Studio Code authentication

### Authenticating with Azure CLI

```bash
# Login to Azure
az login

# If using a specific tenant
az login --tenant <tenant-id>

# Verify authentication
az account show
```

## Dry Run Mode

To preview what tables would be created without making changes:

```bash
python solution_analyzer_upload_to_kusto.py \
    --cluster "https://mycluster.eastus.kusto.windows.net" \
    --database "MyDatabase" \
    --dry-run
```

## Querying the Data in Kusto

Once uploaded, you can query the data using KQL. Here are some example queries:

### Find all tables for a solution

```kql
solution_analyzer_mapping
| where solution_name == "Microsoft 365"
| distinct table_name
```

### Find connectors by collection method

```kql
solution_analyzer_connectors_lookup
| where collection_method == "AMA"
| project connector_id, connector_title, collection_method_reason
```

### Get table metadata

```kql
solution_analyzer_table_reference_lookup
| where table_name == "SecurityEvent"
| project table_name, category, basic_logs_eligible, supports_transformations
```

### Join tables with solutions

```kql
solution_analyzer_mapping
| join kind=leftouter solution_analyzer_tables_lookup on table_name
| project solution_name, table_name, category, collection_method
```

### Find content items for a solution

```kql
solution_analyzer_content_items_lookup
| where solution_name == "Microsoft 365"
| summarize count() by content_type
```

### Get tables used by analytics rules

```kql
solution_analyzer_content_tables_mapping
| where content_type == "analytics_rule"
| summarize solutions=make_set(solution_name) by table_name
| order by array_length(solutions) desc
```
