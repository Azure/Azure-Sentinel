#!/usr/bin/env python3
"""
Generate a report of all Microsoft Sentinel solutions that have data connectors.

This script reads the solutions.csv and connectors.csv files generated by
map_solutions_connectors_tables.py and produces a comprehensive report showing
which solutions have connectors and their associated details.

Output formats:
- Markdown report (solutions_with_connectors_report.md)
- CSV export (solutions_with_connectors.csv)
"""

import argparse
import csv
import sys
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Set

DEFAULT_SOLUTIONS_CSV = "solutions.csv"
DEFAULT_CONNECTORS_CSV = "connectors.csv"
DEFAULT_MAPPING_CSV = "solutions_connectors_tables_mapping.csv"
DEFAULT_OUTPUT_MD = "solutions_with_connectors_report.md"
DEFAULT_OUTPUT_CSV = "solutions_with_connectors.csv"


def load_csv(file_path: Path) -> List[Dict[str, str]]:
    """Load a CSV file and return a list of dictionaries."""
    if not file_path.exists():
        raise FileNotFoundError(f"CSV file not found: {file_path}")
    
    rows = []
    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append(row)
    return rows


def get_solution_connectors(
    solutions: List[Dict[str, str]],
    connectors: List[Dict[str, str]],
    mapping: List[Dict[str, str]]
) -> Dict[str, Dict[str, Any]]:
    """
    Build a mapping of solutions to their connectors using the mapping CSV.
    
    Returns:
        Dictionary mapping solution_name -> {
            'solution_info': solution row,
            'connectors': list of connector rows with their details
        }
    """
    # Build solution info lookup
    solution_info_lookup: Dict[str, Dict[str, str]] = {}
    for sol in solutions:
        sol_name = sol.get('solution_name', '')
        if sol_name:
            solution_info_lookup[sol_name] = sol
    
    # Build connector info lookup (by connector_id)
    connector_info_lookup: Dict[str, Dict[str, str]] = {}
    for conn in connectors:
        conn_id = conn.get('connector_id', '')
        if conn_id:
            connector_info_lookup[conn_id] = conn
    
    # Group by solution, collecting unique connector IDs
    solution_connectors: Dict[str, Set[str]] = defaultdict(set)
    for row in mapping:
        sol_name = row.get('solution_name', '')
        conn_id = row.get('connector_id', '')
        if sol_name and conn_id:
            solution_connectors[sol_name].add(conn_id)
    
    # Build final result
    result: Dict[str, Dict[str, Any]] = {}
    for sol_name, conn_ids in solution_connectors.items():
        if sol_name not in solution_info_lookup:
            continue
        
        # Get connector details for each connector ID
        connectors_list = []
        for conn_id in sorted(conn_ids):
            if conn_id in connector_info_lookup:
                connectors_list.append(connector_info_lookup[conn_id])
            else:
                # Create minimal entry if connector not in connectors.csv
                connectors_list.append({'connector_id': conn_id})
        
        if connectors_list:
            result[sol_name] = {
                'solution_info': solution_info_lookup[sol_name],
                'connectors': connectors_list
            }
    
    return result


def generate_markdown_report(
    solutions_with_connectors: Dict[str, Dict[str, Any]],
    output_path: Path
) -> None:
    """Generate a markdown report of solutions with connectors."""
    
    lines = []
    lines.append("# Microsoft Sentinel Solutions with Data Connectors")
    lines.append("")
    lines.append(f"*Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
    lines.append("")
    
    # Summary statistics
    total_solutions = len(solutions_with_connectors)
    total_connectors = sum(len(s['connectors']) for s in solutions_with_connectors.values())
    
    # Count connectors by collection method
    method_counts: Dict[str, int] = defaultdict(int)
    for sol_data in solutions_with_connectors.values():
        for conn in sol_data['connectors']:
            method = conn.get('collection_method', 'Unknown')
            method_counts[method] += 1
    
    lines.append("## Summary")
    lines.append("")
    lines.append(f"- **Total Solutions with Connectors:** {total_solutions}")
    lines.append(f"- **Total Connectors:** {total_connectors}")
    lines.append("")
    
    lines.append("### Collection Method Distribution")
    lines.append("")
    lines.append("| Collection Method | Count | Percentage |")
    lines.append("|-------------------|-------|------------|")
    for method in sorted(method_counts.keys(), key=lambda m: method_counts[m], reverse=True):
        count = method_counts[method]
        pct = (count / total_connectors * 100) if total_connectors > 0 else 0
        lines.append(f"| {method} | {count} | {pct:.1f}% |")
    lines.append("")
    
    # Table of all solutions with connectors
    lines.append("## Solutions Overview")
    lines.append("")
    lines.append("| Solution | # Connectors | Publisher | Support | Category |")
    lines.append("|----------|--------------|-----------|---------|----------|")
    
    for sol_name in sorted(solutions_with_connectors.keys(), key=str.lower):
        sol_data = solutions_with_connectors[sol_name]
        sol_info = sol_data['solution_info']
        conn_count = len(sol_data['connectors'])
        publisher = sol_info.get('solution_support_name', sol_info.get('solution_author_name', 'N/A'))
        support = sol_info.get('solution_support_tier', 'N/A')
        categories = sol_info.get('solution_categories', 'N/A')
        # Truncate long categories
        if len(categories) > 40:
            categories = categories[:37] + "..."
        # Create solution link
        solution_folder = sol_info.get('solution_folder', '')
        if solution_folder:
            sol_link = f"[{sol_name}]({solution_folder})"
        else:
            sol_link = sol_name
        lines.append(f"| {sol_link} | {conn_count} | {publisher} | {support} | {categories} |")
    lines.append("")
    
    # Write the markdown file
    output_path.write_text('\n'.join(lines), encoding='utf-8')
    print(f"Generated markdown report: {output_path}")


def generate_csv_export(
    solutions_with_connectors: Dict[str, Dict[str, Any]],
    output_path: Path
) -> None:
    """Generate a CSV export of solutions with connectors."""
    
    fieldnames = [
        'solution_name',
        'solution_folder',
        'publisher',
        'support_tier',
        'categories',
        'version',
        'connector_count',
        'connector_id',
        'connector_title',
        'collection_method',
        'tables',
        'solution_github_link',
        'connector_github_link'
    ]
    
    rows = []
    for sol_name in sorted(solutions_with_connectors.keys(), key=str.lower):
        sol_data = solutions_with_connectors[sol_name]
        sol_info = sol_data['solution_info']
        connectors = sol_data['connectors']
        
        for conn in connectors:
            row = {
                'solution_name': sol_name,
                'solution_folder': sol_info.get('solution_folder', ''),
                'publisher': sol_info.get('solution_support_name', sol_info.get('solution_author_name', '')),
                'support_tier': sol_info.get('solution_support_tier', ''),
                'categories': sol_info.get('solution_categories', ''),
                'version': sol_info.get('solution_version', ''),
                'connector_count': len(connectors),
                'connector_id': conn.get('connector_id', ''),
                'connector_title': conn.get('connector_title', ''),
                'collection_method': conn.get('collection_method', ''),
                'tables': conn.get('tables', ''),
                'solution_github_link': sol_info.get('solution_folder', ''),
                'connector_github_link': conn.get('connector_files', '')
            }
            rows.append(row)
    
    with open(output_path, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)
    
    print(f"Generated CSV export: {output_path} ({len(rows)} rows)")


def main():
    parser = argparse.ArgumentParser(
        description="Generate a report of Microsoft Sentinel solutions with data connectors"
    )
    parser.add_argument(
        '--solutions-csv',
        type=Path,
        default=DEFAULT_SOLUTIONS_CSV,
        help=f"Path to solutions CSV file (default: {DEFAULT_SOLUTIONS_CSV})"
    )
    parser.add_argument(
        '--connectors-csv',
        type=Path,
        default=DEFAULT_CONNECTORS_CSV,
        help=f"Path to connectors CSV file (default: {DEFAULT_CONNECTORS_CSV})"
    )
    parser.add_argument(
        '--mapping-csv',
        type=Path,
        default=DEFAULT_MAPPING_CSV,
        help=f"Path to solutions-connectors-tables mapping CSV file (default: {DEFAULT_MAPPING_CSV})"
    )
    parser.add_argument(
        '--output-md',
        type=Path,
        default=DEFAULT_OUTPUT_MD,
        help=f"Path for markdown report output (default: {DEFAULT_OUTPUT_MD})"
    )
    parser.add_argument(
        '--output-csv',
        type=Path,
        default=DEFAULT_OUTPUT_CSV,
        help=f"Path for CSV export output (default: {DEFAULT_OUTPUT_CSV})"
    )
    parser.add_argument(
        '--no-md',
        action='store_true',
        help="Skip generating markdown report"
    )
    parser.add_argument(
        '--no-csv',
        action='store_true',
        help="Skip generating CSV export"
    )
    
    args = parser.parse_args()
    
    # Resolve paths relative to script directory if not absolute
    script_dir = Path(__file__).parent
    solutions_csv = args.solutions_csv if args.solutions_csv.is_absolute() else script_dir / args.solutions_csv
    connectors_csv = args.connectors_csv if args.connectors_csv.is_absolute() else script_dir / args.connectors_csv
    mapping_csv = args.mapping_csv if args.mapping_csv.is_absolute() else script_dir / args.mapping_csv
    output_md = args.output_md if args.output_md.is_absolute() else script_dir / args.output_md
    output_csv = args.output_csv if args.output_csv.is_absolute() else script_dir / args.output_csv
    
    try:
        # Load data
        print(f"Loading solutions from {solutions_csv}...")
        solutions = load_csv(solutions_csv)
        print(f"  Loaded {len(solutions)} solutions")
        
        print(f"Loading connectors from {connectors_csv}...")
        connectors = load_csv(connectors_csv)
        print(f"  Loaded {len(connectors)} connectors")
        
        print(f"Loading mapping from {mapping_csv}...")
        mapping = load_csv(mapping_csv)
        print(f"  Loaded {len(mapping)} mappings")
        
        # Build mapping
        solutions_with_connectors = get_solution_connectors(solutions, connectors, mapping)
        print(f"\nFound {len(solutions_with_connectors)} solutions with data connectors")
        
        # Generate outputs
        if not args.no_md:
            generate_markdown_report(solutions_with_connectors, output_md)
        
        if not args.no_csv:
            generate_csv_export(solutions_with_connectors, output_csv)
        
        print("\nDone!")
        return 0
        
    except FileNotFoundError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
